{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# USUALLY PREINSTALLED IN COLAB #################\n",
    "# !pip install numpy pandas sqlalchemy sqlglot\n",
    "# !pip install torch transformers spacy \n",
    "\n",
    "!pip install Levenshtein\n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes\n",
    "!pip install sentence-transformers\n",
    "!pip install spacy-transformers\n",
    "\n",
    "!python -m spacy download en_core_web_md\n",
    "!python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data\n",
    "\n",
    "We had previously downloaded the [Young People Survey Dataset](https://www.kaggle.com/datasets/miroslavsabo/young-people-survey) from Kaggle and loaded it into a `sqlite` DB. Let's take a look at the data once more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Music</th>\n",
       "      <th>Slow_songs_or_fast_songs</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Folk</th>\n",
       "      <th>Country</th>\n",
       "      <th>Classical_music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Metal_or_Hardrock</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Number_of_siblings</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Left_right_handed</th>\n",
       "      <th>Education</th>\n",
       "      <th>Only_child</th>\n",
       "      <th>Village_town</th>\n",
       "      <th>House_block_of_flats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>yes</td>\n",
       "      <td>city</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Music  Slow_songs_or_fast_songs  Dance  Folk  Country  Classical_music  \\\n",
       "0    5.0                       3.0    2.0   1.0      2.0              2.0   \n",
       "1    4.0                       4.0    2.0   1.0      1.0              1.0   \n",
       "2    5.0                       5.0    2.0   2.0      3.0              4.0   \n",
       "3    5.0                       3.0    2.0   1.0      1.0              1.0   \n",
       "4    5.0                       3.0    4.0   3.0      2.0              4.0   \n",
       "\n",
       "   Musical  Pop  Rock  Metal_or_Hardrock  ...   Age  Height  Weight  \\\n",
       "0      1.0  5.0   5.0                1.0  ...  20.0   163.0    48.0   \n",
       "1      2.0  3.0   5.0                4.0  ...  19.0   163.0    58.0   \n",
       "2      5.0  3.0   5.0                3.0  ...  20.0   176.0    67.0   \n",
       "3      1.0  2.0   2.0                1.0  ...  22.0   172.0    59.0   \n",
       "4      3.0  5.0   3.0                1.0  ...  20.0   170.0    59.0   \n",
       "\n",
       "   Number_of_siblings  Gender  Left_right_handed                Education  \\\n",
       "0                 1.0  female       right handed  college/bachelor degree   \n",
       "1                 2.0  female       right handed  college/bachelor degree   \n",
       "2                 2.0  female       right handed         secondary school   \n",
       "3                 1.0  female       right handed  college/bachelor degree   \n",
       "4                 1.0  female       right handed         secondary school   \n",
       "\n",
       "   Only_child  Village_town  House_block_of_flats  \n",
       "0          no       village        block of flats  \n",
       "1          no          city        block of flats  \n",
       "2          no          city        block of flats  \n",
       "3         yes          city        house/bungalow  \n",
       "4          no       village        house/bungalow  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/young_people_survey.csv')\n",
    "df.columns = df.columns.str.replace('-','')\n",
    "df.columns = df.columns.str.replace(' ','_')\n",
    "df.columns = df.columns.str.replace('__','_')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking the SQLite DB\n",
    "\n",
    "Let's connect to our `sqlite` file and look at its contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table already exists in SQLite DB\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(f\"sqlite:///mysqlitedb.db\")\n",
    "table_name = 'young_people_survey'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('data/young_people_survey.csv')\n",
    "    df.to_sql(table_name, engine, index=False)\n",
    "    print('Data loaded from CSV file!')\n",
    "except ValueError as e:\n",
    "    err_msg = e.args[0]\n",
    "    if 'already exists' in err_msg:\n",
    "        print('Table already exists in SQLite DB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>tbl_name</th>\n",
       "      <th>rootpage</th>\n",
       "      <th>sql</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>table</td>\n",
       "      <td>young-people-survey</td>\n",
       "      <td>young-people-survey</td>\n",
       "      <td>2</td>\n",
       "      <td>CREATE TABLE \"young-people-survey\" (\\n\\t\"Music...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type                 name             tbl_name  rootpage  \\\n",
       "0  table  young-people-survey  young-people-survey         2   \n",
       "\n",
       "                                                 sql  \n",
       "0  CREATE TABLE \"young-people-survey\" (\\n\\t\"Music...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sqlite_master = pd.read_sql_query(\"SELECT * FROM sqlite_master\", conn)\n",
    "\n",
    "sqlite_master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As before, we can get the table DDL from the `sqlite_master` table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"young-people-survey\" (\n",
      "\t\"Music\" FLOAT, \n",
      "\t\"Slow songs or fast songs\" FLOAT, \n",
      "\t\"Dance\" FLOAT, \n",
      "\t\"Folk\" FLOAT, \n",
      "\t\"Country\" FLOAT, \n",
      "\t\"Classical music\" FLOAT, \n",
      "\t\"Musical\" FLOAT, \n",
      "\t\"Pop\" FLOAT, \n",
      "\t\"Rock\" FLOAT, \n",
      "\t\"Metal or Hardrock\" FLOAT, \n",
      "\t\"Punk\" FLOAT, \n",
      "\t\"Hiphop, Rap\" FLOAT, \n",
      "\t\"Reggae, Ska\" FLOAT, \n",
      "\t\"Swing, Jazz\" FLOAT, \n",
      "\t\"Rock n roll\" FLOAT, \n",
      "\t\"Alternative\" FLOAT, \n",
      "\t\"Latino\" FLOAT, \n",
      "\t\"Techno, Trance\" FLOAT, \n",
      "\t\"Opera\" FLOAT, \n",
      "\t\"Movies\" FLOAT, \n",
      "\t\"Horror\" FLOAT, \n",
      "\t\"Thriller\" FLOAT, \n",
      "\t\"Comedy\" FLOAT, \n",
      "\t\"Romantic\" FLOAT, \n",
      "\t\"Sci-fi\" FLOAT, \n",
      "\t\"War\" FLOAT, \n",
      "\t\"Fantasy/Fairy tales\" FLOAT, \n",
      "\t\"Animated\" FLOAT, \n",
      "\t\"Documentary\" FLOAT, \n",
      "\t\"Western\" FLOAT, \n",
      "\t\"Action\" FLOAT, \n",
      "\t\"History\" FLOAT, \n",
      "\t\"Psychology\" FLOAT, \n",
      "\t\"Politics\" FLOAT, \n",
      "\t\"Mathematics\" FLOAT, \n",
      "\t\"Physics\" FLOAT, \n",
      "\t\"Internet\" FLOAT, \n",
      "\t\"PC\" FLOAT, \n",
      "\t\"Economy Management\" FLOAT, \n",
      "\t\"Biology\" FLOAT, \n",
      "\t\"Chemistry\" FLOAT, \n",
      "\t\"Reading\" FLOAT, \n",
      "\t\"Geography\" FLOAT, \n",
      "\t\"Foreign languages\" FLOAT, \n",
      "\t\"Medicine\" FLOAT, \n",
      "\t\"Law\" FLOAT, \n",
      "\t\"Cars\" FLOAT, \n",
      "\t\"Art exhibitions\" FLOAT, \n",
      "\t\"Religion\" FLOAT, \n",
      "\t\"Countryside, outdoors\" FLOAT, \n",
      "\t\"Dancing\" FLOAT, \n",
      "\t\"Musical instruments\" FLOAT, \n",
      "\t\"Writing\" FLOAT, \n",
      "\t\"Passive sport\" FLOAT, \n",
      "\t\"Active sport\" FLOAT, \n",
      "\t\"Gardening\" FLOAT, \n",
      "\t\"Celebrities\" FLOAT, \n",
      "\t\"Shopping\" FLOAT, \n",
      "\t\"Science and technology\" FLOAT, \n",
      "\t\"Theatre\" FLOAT, \n",
      "\t\"Fun with friends\" FLOAT, \n",
      "\t\"Adrenaline sports\" FLOAT, \n",
      "\t\"Pets\" FLOAT, \n",
      "\t\"Flying\" FLOAT, \n",
      "\t\"Storm\" FLOAT, \n",
      "\t\"Darkness\" FLOAT, \n",
      "\t\"Heights\" FLOAT, \n",
      "\t\"Spiders\" FLOAT, \n",
      "\t\"Snakes\" BIGINT, \n",
      "\t\"Rats\" FLOAT, \n",
      "\t\"Ageing\" FLOAT, \n",
      "\t\"Dangerous dogs\" FLOAT, \n",
      "\t\"Fear of public speaking\" FLOAT, \n",
      "\t\"Smoking\" TEXT, \n",
      "\t\"Alcohol\" TEXT, \n",
      "\t\"Healthy eating\" FLOAT, \n",
      "\t\"Daily events\" FLOAT, \n",
      "\t\"Prioritising workload\" FLOAT, \n",
      "\t\"Writing notes\" FLOAT, \n",
      "\t\"Workaholism\" FLOAT, \n",
      "\t\"Thinking ahead\" FLOAT, \n",
      "\t\"Final judgement\" FLOAT, \n",
      "\t\"Reliability\" FLOAT, \n",
      "\t\"Keeping promises\" FLOAT, \n",
      "\t\"Loss of interest\" FLOAT, \n",
      "\t\"Friends versus money\" FLOAT, \n",
      "\t\"Funniness\" FLOAT, \n",
      "\t\"Fake\" FLOAT, \n",
      "\t\"Criminal damage\" FLOAT, \n",
      "\t\"Decision making\" FLOAT, \n",
      "\t\"Elections\" FLOAT, \n",
      "\t\"Self-criticism\" FLOAT, \n",
      "\t\"Judgment calls\" FLOAT, \n",
      "\t\"Hypochondria\" FLOAT, \n",
      "\t\"Empathy\" FLOAT, \n",
      "\t\"Eating to survive\" BIGINT, \n",
      "\t\"Giving\" FLOAT, \n",
      "\t\"Compassion to animals\" FLOAT, \n",
      "\t\"Borrowed stuff\" FLOAT, \n",
      "\t\"Loneliness\" FLOAT, \n",
      "\t\"Cheating in school\" FLOAT, \n",
      "\t\"Health\" FLOAT, \n",
      "\t\"Changing the past\" FLOAT, \n",
      "\t\"God\" FLOAT, \n",
      "\t\"Dreams\" BIGINT, \n",
      "\t\"Charity\" FLOAT, \n",
      "\t\"Number of friends\" BIGINT, \n",
      "\t\"Punctuality\" TEXT, \n",
      "\t\"Lying\" TEXT, \n",
      "\t\"Waiting\" FLOAT, \n",
      "\t\"New environment\" FLOAT, \n",
      "\t\"Mood swings\" FLOAT, \n",
      "\t\"Appearence and gestures\" FLOAT, \n",
      "\t\"Socializing\" FLOAT, \n",
      "\t\"Achievements\" FLOAT, \n",
      "\t\"Responding to a serious letter\" FLOAT, \n",
      "\t\"Children\" FLOAT, \n",
      "\t\"Assertiveness\" FLOAT, \n",
      "\t\"Getting angry\" FLOAT, \n",
      "\t\"Knowing the right people\" FLOAT, \n",
      "\t\"Public speaking\" FLOAT, \n",
      "\t\"Unpopularity\" FLOAT, \n",
      "\t\"Life struggles\" FLOAT, \n",
      "\t\"Happiness in life\" FLOAT, \n",
      "\t\"Energy levels\" FLOAT, \n",
      "\t\"Small - big dogs\" FLOAT, \n",
      "\t\"Personality\" FLOAT, \n",
      "\t\"Finding lost valuables\" FLOAT, \n",
      "\t\"Getting up\" FLOAT, \n",
      "\t\"Interests or hobbies\" FLOAT, \n",
      "\t\"Parents' advice\" FLOAT, \n",
      "\t\"Questionnaires or polls\" FLOAT, \n",
      "\t\"Internet usage\" TEXT, \n",
      "\t\"Finances\" FLOAT, \n",
      "\t\"Shopping centres\" FLOAT, \n",
      "\t\"Branded clothing\" FLOAT, \n",
      "\t\"Entertainment spending\" FLOAT, \n",
      "\t\"Spending on looks\" FLOAT, \n",
      "\t\"Spending on gadgets\" BIGINT, \n",
      "\t\"Spending on healthy eating\" FLOAT, \n",
      "\t\"Age\" FLOAT, \n",
      "\t\"Height\" FLOAT, \n",
      "\t\"Weight\" FLOAT, \n",
      "\t\"Number of siblings\" FLOAT, \n",
      "\t\"Gender\" TEXT, \n",
      "\t\"Left - right handed\" TEXT, \n",
      "\t\"Education\" TEXT, \n",
      "\t\"Only child\" TEXT, \n",
      "\t\"Village - town\" TEXT, \n",
      "\t\"House - block of flats\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "sqlite_master['sql_fmt'] = sqlite_master['sql'].apply(lambda z: [x.strip().strip(',').rsplit(' ', maxsplit=1) for x in z.split('\\n')[1:-1]])\n",
    "\n",
    "table_desc_dict = {}\n",
    "for _, row in sqlite_master.iterrows():\n",
    "    table_desc_dict[row['name']] = row['sql']\n",
    "\n",
    "schema = table_desc_dict[table_name]\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the LLM - SQLCoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import sqlparse\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"defog/sqlcoder-7b-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    # torch_dtype=torch.float16, # Disable if enabling the below line\n",
    "    load_in_8bit=True, # Disable if enabling the above line\n",
    "    device_map=\"auto\",\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(prompt):\n",
    "    \n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=400,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "    )\n",
    "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    # empty cache so that you do generate more results w/o memory crashing\n",
    "    # particularly important on Colab – memory management is much more straightforward\n",
    "    # when running on an inference service\n",
    "    return outputs[0].split(\"[SQL]\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting - NL2SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "question1 = 'Fetch the count of male and female who are right handed and are very interested in Cars ?'\n",
    "question2 = 'Fetch the count of \\'male\\' and \\'female\\' who are \\'right handed\\' and are very interested in Cars ?'\n",
    "question3 = 'Fetch the count of \\'male\\' and \\'female\\' who are \\'right handed\\' and afraid of public speaking ?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"### Task\n",
    "Generate a SQL query to answer [QUESTION]{question}[/QUESTION] \n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "\n",
    "## Database Schema \n",
    "This query will run on a database whose schema is represented in this string: {db_schema} \n",
    "\n",
    "### Answer \n",
    "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION] [SQL]\n",
    "\"\"\"\n",
    "\n",
    "prompt1 = prompt_template.format(question=question1, db_schema = schema)\n",
    "print(prompt1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql1 = generate_query(prompt1)\n",
    "print(sqlparse.format(generated_sql1, reindent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"sqlite:///mysqlitedb.db\")\n",
    "with engine.connect() as conn, conn.begin():\n",
    "    query_result1 = pd.read_sql_query(generated_sql1, conn)\n",
    "\n",
    "print(query_result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Gender'] == 'female') & (df['Left_right_handed'] == 'right handed') & (df['Cars'] > 4)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Preprocesses: LLM Prompt Pruning\n",
    "\n",
    "Even though LLMs are offering longer context lengths every day, they still tend to get [lost in the middle](https://arxiv.org/abs/2307.03172), i.e. the model pays most attention to the beginning and the end of the prompt. Since we are adding our table DDL in the prompt as context and DDLs can contain tables numbering in the multiples of hundreds, it is seen that the LLM often fails to \"pick\" the relevant column names, especially if they occur in the middle of the DDL.\n",
    "\n",
    "To fix this, we \"prune\" the DDL, i.e. we do not include all the columns but only those which we deem relevant to our question. With this shortened DDL, the LLM should have a much easier time selecting the correct column and also leaves more room in the context window for the generated SQL.\n",
    "\n",
    "To find the columns which are \"relevant\" to our question, we compute a similarity metric between the column names/descriptions and the question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud-user/data/miniconda3/envs/myenv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import torch\n",
    "import sqlglot\n",
    "import numpy as np\n",
    "import os, re, logging, pickle\n",
    "import torch.nn.functional as F\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use an embedding model called `mxbai-embed-large-v1` to compute the embeddings for our column names and our question. We also use a parameter `top_k` which is the number of columns, ordered in descending order of similarity score, we want to select from the complete table DDL.\n",
    "\n",
    "In addition to this, we also include all columns of type `DATE` or `TIMESTAMP` if we detect any time-related terms in our question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Embedding Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methods\n",
    "\n",
    "#### 1. Retrieve top-k columns using KNN model\n",
    "#### 2. Create schema from top-k columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_(query: str, all_embs: torch.tensor, top_k: int, threshold: float) -> tuple[torch.tensor, torch.tensor]:\n",
    "    \n",
    "    \"\"\"\n",
    "    Get top most similar columns' embeddings to query using cosine similarity.\n",
    "    \"\"\"\n",
    "    encoder = SentenceTransformer(\"mixedbread-ai/mxbai-embed-large-v1\", device='cpu')\n",
    "    query_emb = encoder.encode(query, convert_to_tensor=True, device='cpu').unsqueeze(0)\n",
    "\n",
    "    similarity_scores = F.cosine_similarity(query_emb, all_embs)\n",
    "    top_results = torch.nonzero(similarity_scores > threshold).squeeze()\n",
    "\n",
    "    # if top_results is empty, return empty tensors\n",
    "    if top_results.numel() == 0:\n",
    "        return torch.tensor([]), torch.tensor([])\n",
    "\n",
    "    # if only 1 result is returned, we need to convert it to a tensor\n",
    "    elif top_results.numel() == 1:\n",
    "        return torch.tensor([similarity_scores[top_results]]), torch.tensor([top_results])\n",
    "    else:\n",
    "        top_k_scores, top_k_indices = torch.topk(similarity_scores[top_results], k=min(top_k, top_results.numel()))\n",
    "        return top_k_scores, top_results[top_k_indices]\n",
    "    \n",
    "    \n",
    "    \n",
    "def format_topk_sql(topk_table_columns: dict[str, list[tuple[str, str, str]]], shuffle: bool) -> str:\n",
    "    if len(topk_table_columns) == 0:\n",
    "        return \"\"\n",
    "\n",
    "    md_str = \"\\n\"\n",
    "    # shuffle the keys in topk_table_columns\n",
    "    table_names = list(topk_table_columns.keys())\n",
    "    if shuffle:\n",
    "        np.random.seed(0)\n",
    "        np.random.shuffle(table_names)\n",
    "    for table_name in table_names:\n",
    "        columns_str = \"\"\n",
    "        columns = topk_table_columns[table_name]\n",
    "        if shuffle:\n",
    "            np.random.seed(0)\n",
    "            np.random.shuffle(columns)\n",
    "        for column_tuple in columns:\n",
    "            if len(column_tuple) > 2:\n",
    "                columns_str += (\n",
    "                    f\"\\n  {column_tuple[0]} {column_tuple[1]}, --{column_tuple[2]}\"\n",
    "                )\n",
    "            else:\n",
    "                columns_str += f\"\\n  {column_tuple[0]} {column_tuple[1]}, \"\n",
    "        md_str += f\"CREATE TABLE {table_name} ({columns_str}\\n);\\n\"\n",
    "    md_str += \"\\n\"\n",
    "    return md_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud-user/data/miniconda3/envs/myenv/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE young-people-survey (\n",
      "  Gender TEXT, --None\n",
      "  Number of siblings FLOAT, --None\n",
      "  Height FLOAT, --None\n",
      "  Age FLOAT, --None\n",
      "  Alternative FLOAT, --None\n",
      ");\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_PATH = 'embs'\n",
    "TOP_K_LIMIT = 25 # number of columns to include in the prompt\n",
    "PRUNE_LIMIT = 5 # minimum number of columns above which a given DDL will be pruned\n",
    "num_cols = 0\n",
    "TAB_DETAILS = []\n",
    "\n",
    "\n",
    "for col in sqlglot.parse_one(schema, dialect='snowflake').find_all(sqlglot.exp.ColumnDef):\n",
    "    num_cols += 1\n",
    "    TAB_DETAILS.append([table_name, col.alias_or_name, col.find(sqlglot.exp.DataType).__str__(), col.find(sqlglot.exp.ColumnConstraint)])\n",
    "        \n",
    "# print(TAB_DETAILS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "column_descriptions = []\n",
    "column_descriptions_typed = []\n",
    "\n",
    "for row in TAB_DETAILS:\n",
    "    tab_name, col_name, col_dtype, col_desc = row\n",
    "\n",
    "    col_str = f\"{tab_name}.{col_name}:{col_desc}\"\n",
    "    col_str_typed = f\"{tab_name}.{col_name},{col_dtype},{col_desc}\"\n",
    "\n",
    "    column_descriptions.append(col_str)\n",
    "    column_descriptions_typed.append(col_str_typed)\n",
    "    \n",
    "column_descriptions_typed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_embs = encoder.encode(column_descriptions, convert_to_tensor=True, device='cpu')\n",
    "\n",
    "\n",
    "# 1a) get top k columns\n",
    "top_k_scores, top_k_indices = knn_(question, column_embs, top_k=5, threshold=0.0)\n",
    "topk_table_columns = {}\n",
    "table_column_names = set()\n",
    "\n",
    "for score, index in zip(top_k_scores, top_k_indices):\n",
    "    table_name, column_info = column_descriptions_typed[index].split(\".\", 1)\n",
    "    column_tuple = re.split(r',\\s*(?![^()]*\\))', column_info, maxsplit=2) #split only on commas outside parantheses\n",
    "    if table_name not in topk_table_columns:\n",
    "        topk_table_columns[table_name] = []\n",
    "    topk_table_columns[table_name].append(column_tuple)\n",
    "    table_column_names.add(f\"{table_name}.{column_tuple[0]}\")\n",
    "    # print(\"INCLUDED by embs: \", column_tuple)\n",
    "\n",
    "topk_table_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b) get columns which match terms in question\n",
    "nlp = spacy.load(\"en_core_web_trf\")\n",
    "question_doc = nlp(question)\n",
    "q_filtered_tokens = [token.lemma_.lower() for token in question_doc if not token.is_stop]\n",
    "q_alpha_tokens = [i for i in q_filtered_tokens if (len(i)>1 and i.isalpha())]\n",
    "\n",
    "\n",
    "TIME_TERMS = ['when', 'time', 'hour', 'minute', 'second', \n",
    "            'day', 'yesterday', 'today', 'tomorrow', \n",
    "            'week', 'month', 'year', \n",
    "            'duration', 'date']\n",
    "\n",
    "time_in_q = False\n",
    "\n",
    "nlp_ner = spacy.load(\"en_core_web_md\")\n",
    "q_ner_doc = nlp_ner(question)\n",
    "ent_types = [w.label_ for w in q_ner_doc.ents]\n",
    "\n",
    "if 'DATE' in ent_types or 'TIME' in ent_types:\n",
    "    time_in_q = True\n",
    "elif any([term in question.lower() for term in TIME_TERMS]):\n",
    "    time_in_q = True\n",
    "elif set(q_alpha_tokens).intersection(set(TIME_TERMS)):\n",
    "    time_in_q = True\n",
    "\n",
    "for col_details in column_descriptions_typed:\n",
    "    table_name, column_info = col_details.split(\".\", 1)\n",
    "    column_tuple = re.split(r',\\s*(?![^()]*\\))', column_info, maxsplit=2) #split only on commas outside parantheses\n",
    "    col_name = column_tuple[0]\n",
    "\n",
    "    if column_tuple in topk_table_columns[table_name]:\n",
    "        # print(\"SKIPPING: \", column_tuple)\n",
    "        continue\n",
    "\n",
    "    # if question concerns time, add time-related columns\n",
    "    if time_in_q and any([timetype in column_tuple[1] for timetype in ['DATE', 'TIMESTAMP']]):\n",
    "        if table_name not in topk_table_columns:\n",
    "            topk_table_columns[table_name] = []\n",
    "        if column_tuple not in topk_table_columns[table_name]:\n",
    "            topk_table_columns[table_name].append(column_tuple)\n",
    "        table_column_names.add(f\"{table_name}.{column_tuple[0]}\")\n",
    "        continue\n",
    "\n",
    "    # if question-token-lemmas overlap with column-token-lemmas, add the column\n",
    "    column_doc = nlp(col_name.replace('_', ' '))\n",
    "    col_tokens = [token.lemma_.lower() for token in column_doc if not token.is_stop]\n",
    "    col_alpha_tokens = [i for i in col_tokens if (len(i)>1 and i.isalpha())]\n",
    "    if set(col_alpha_tokens).intersection(set(q_alpha_tokens)):\n",
    "        if table_name not in topk_table_columns:\n",
    "            topk_table_columns[table_name] = []\n",
    "        if column_tuple not in topk_table_columns[table_name]:\n",
    "            topk_table_columns[table_name].append(column_tuple)\n",
    "        table_column_names.add(f\"{table_name}.{column_tuple[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) format metadata string\n",
    "pruned_schema = format_topk_sql(topk_table_columns, shuffle=False)\n",
    "print(pruned_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Pruned Prompting - NL2SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task\n",
      "Generate a SQL query to answer [QUESTION]Fetch the count of male and female in the data.[/QUESTION] \n",
      "\n",
      "### Instructions\n",
      "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
      "\n",
      "## Database Schema \n",
      "This query will run on a database whose schema is represented in this string: \n",
      "CREATE TABLE young-people-survey (\n",
      "  Gender TEXT, --None\n",
      "  Number of siblings FLOAT, --None\n",
      "  Height FLOAT, --None\n",
      "  Age FLOAT, --None\n",
      "  Alternative FLOAT, --None\n",
      ");\n",
      "\n",
      " \n",
      "\n",
      "### Answer \n",
      "Given the database schema, here is the SQL query that answers [QUESTION]Fetch the count of male and female in the data.[/QUESTION] [SQL]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"### Task\n",
    "Generate a SQL query to answer [QUESTION]{question}[/QUESTION] \n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "\n",
    "## Database Schema \n",
    "This query will run on a database whose schema is represented in this string: {db_schema} \n",
    "\n",
    "### Answer \n",
    "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION] [SQL]\n",
    "\"\"\"\n",
    "\n",
    "prompt2 = prompt_template.format(question=question3, db_schema = pruned_schema)\n",
    "print(prompt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql2 = generate_query(prompt2)\n",
    "print(sqlparse.format(generated_sql2, reindent=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding Instruction in Pruned Prompting - NL2SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"### Task\n",
    "Generate a SQL query to answer [QUESTION]{question}[/QUESTION] \n",
    "\n",
    "### Instructions\n",
    "- Not afraid at all 1-2-3-4-5 Very afraid of (integer)\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "\n",
    "## Database Schema \n",
    "This query will run on a database whose schema is represented in this string: {db_schema} \n",
    "\n",
    "### Answer \n",
    "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION] [SQL]\n",
    "\"\"\"\n",
    "\n",
    "prompt3 = prompt_template.format(question=question3, db_schema = pruned_schema)\n",
    "print(prompt3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql3 = generate_query(prompt3)\n",
    "print(sqlparse.format(generated_sql3, reindent=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"sqlite:///mysqlitedb.db\")\n",
    "with engine.connect() as conn, conn.begin():\n",
    "    query_result3 = pd.read_sql_query(generated_sql3, conn)\n",
    "\n",
    "print(query_result3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[(df['Gender'] == 'female') & (df['Left_right_handed'] == 'right handed') & (df['Fear-of_public_speaking'] > 1)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](assets/implementation-NL2SQL.PNG)   -->\n",
    "<img src='assets/implementation-NL2SQL.PNG'>  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
