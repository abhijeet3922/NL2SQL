{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](assets/Introuction-NL2SQL.PNG)   -->\n",
    "<img src='assets/Introuction-NL2SQL.PNG'>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "################# USUALLY PREINSTALLED IN COLAB #################\n",
    "# !pip install numpy pandas sqlalchemy sqlglot\n",
    "# !pip install torch transformers spacy \n",
    "\n",
    "!pip install Levenshtein\n",
    "!pip install accelerate\n",
    "!pip install bitsandbytes\n",
    "!pip install sentence-transformers\n",
    "!pip install spacy-transformers\n",
    "\n",
    "# !python -m spacy download en_core_web_md\n",
    "# !python -m spacy download en_core_web_trf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get CSV data from Kaggle\n",
    "\n",
    "We are using the [Young People Survey Dataset](https://www.kaggle.com/datasets/miroslavsabo/young-people-survey) from Kaggle. The primary reason for choosing this dataset is because it has a pretty large number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Music</th>\n",
       "      <th>Slow songs or fast songs</th>\n",
       "      <th>Dance</th>\n",
       "      <th>Folk</th>\n",
       "      <th>Country</th>\n",
       "      <th>Classical music</th>\n",
       "      <th>Musical</th>\n",
       "      <th>Pop</th>\n",
       "      <th>Rock</th>\n",
       "      <th>Metal or Hardrock</th>\n",
       "      <th>...</th>\n",
       "      <th>Age</th>\n",
       "      <th>Height</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Number of siblings</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Left - right handed</th>\n",
       "      <th>Education</th>\n",
       "      <th>Only child</th>\n",
       "      <th>Village - town</th>\n",
       "      <th>House - block of flats</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>176.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>city</td>\n",
       "      <td>block of flats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>172.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>college/bachelor degree</td>\n",
       "      <td>yes</td>\n",
       "      <td>city</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>female</td>\n",
       "      <td>right handed</td>\n",
       "      <td>secondary school</td>\n",
       "      <td>no</td>\n",
       "      <td>village</td>\n",
       "      <td>house/bungalow</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 150 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Music  Slow songs or fast songs  Dance  Folk  Country  Classical music  \\\n",
       "0    5.0                       3.0    2.0   1.0      2.0              2.0   \n",
       "1    4.0                       4.0    2.0   1.0      1.0              1.0   \n",
       "2    5.0                       5.0    2.0   2.0      3.0              4.0   \n",
       "3    5.0                       3.0    2.0   1.0      1.0              1.0   \n",
       "4    5.0                       3.0    4.0   3.0      2.0              4.0   \n",
       "\n",
       "   Musical  Pop  Rock  Metal or Hardrock  ...   Age  Height  Weight  \\\n",
       "0      1.0  5.0   5.0                1.0  ...  20.0   163.0    48.0   \n",
       "1      2.0  3.0   5.0                4.0  ...  19.0   163.0    58.0   \n",
       "2      5.0  3.0   5.0                3.0  ...  20.0   176.0    67.0   \n",
       "3      1.0  2.0   2.0                1.0  ...  22.0   172.0    59.0   \n",
       "4      3.0  5.0   3.0                1.0  ...  20.0   170.0    59.0   \n",
       "\n",
       "   Number of siblings  Gender  Left - right handed                Education  \\\n",
       "0                 1.0  female         right handed  college/bachelor degree   \n",
       "1                 2.0  female         right handed  college/bachelor degree   \n",
       "2                 2.0  female         right handed         secondary school   \n",
       "3                 1.0  female         right handed  college/bachelor degree   \n",
       "4                 1.0  female         right handed         secondary school   \n",
       "\n",
       "   Only child  Village - town  House - block of flats  \n",
       "0          no         village          block of flats  \n",
       "1          no            city          block of flats  \n",
       "2          no            city          block of flats  \n",
       "3         yes            city          house/bungalow  \n",
       "4          no         village          house/bungalow  \n",
       "\n",
       "[5 rows x 150 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/young_people_survey.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data into SQLite DB\n",
    "\n",
    "For a demonstration of real-world usecases, we will load our CSV data into a database. Once done, we will extract the DDL or the Database Definition Language, i.e. the commands which actually define our table, or more accurately, our table schema.\n",
    "\n",
    "We will use `sqlite` for this usecase but you can use your DB of choice. You will need to of course install any relevant libraries to communicate with your DB using python.\n",
    "For simplicity's sake, we use built-in functions of Pandas to load and read data from the database. Of course, you can use your DB connector as well to peform these operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded from CSV file!\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(f\"sqlite:///mysqlitedb.db\")\n",
    "table_name = 'young_people_survey'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv('data/young_people_survey.csv')\n",
    "    df.to_sql(table_name, engine, index=False)\n",
    "    print('Data loaded from CSV file!')\n",
    "except ValueError as e:\n",
    "    err_msg = e.args[0]\n",
    "    if 'already exists' in err_msg:\n",
    "        print('Table already exists in SQLite DB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sqlite` databases contain a table known as `sqlite_master` which contains the details of all tables hosted by the database. This table contains the \"derived\" DDL for each table. If you are using any other database, the process for getting the DDL for your table might be different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CREATE TABLE \"young-people-survey\" (\n",
      "\t\"Music\" FLOAT, \n",
      "\t\"Slow songs or fast songs\" FLOAT, \n",
      "\t\"Dance\" FLOAT, \n",
      "\t\"Folk\" FLOAT, \n",
      "\t\"Country\" FLOAT, \n",
      "\t\"Classical music\" FLOAT, \n",
      "\t\"Musical\" FLOAT, \n",
      "\t\"Pop\" FLOAT, \n",
      "\t\"Rock\" FLOAT, \n",
      "\t\"Metal or Hardrock\" FLOAT, \n",
      "\t\"Punk\" FLOAT, \n",
      "\t\"Hiphop, Rap\" FLOAT, \n",
      "\t\"Reggae, Ska\" FLOAT, \n",
      "\t\"Swing, Jazz\" FLOAT, \n",
      "\t\"Rock n roll\" FLOAT, \n",
      "\t\"Alternative\" FLOAT, \n",
      "\t\"Latino\" FLOAT, \n",
      "\t\"Techno, Trance\" FLOAT, \n",
      "\t\"Opera\" FLOAT, \n",
      "\t\"Movies\" FLOAT, \n",
      "\t\"Horror\" FLOAT, \n",
      "\t\"Thriller\" FLOAT, \n",
      "\t\"Comedy\" FLOAT, \n",
      "\t\"Romantic\" FLOAT, \n",
      "\t\"Sci-fi\" FLOAT, \n",
      "\t\"War\" FLOAT, \n",
      "\t\"Fantasy/Fairy tales\" FLOAT, \n",
      "\t\"Animated\" FLOAT, \n",
      "\t\"Documentary\" FLOAT, \n",
      "\t\"Western\" FLOAT, \n",
      "\t\"Action\" FLOAT, \n",
      "\t\"History\" FLOAT, \n",
      "\t\"Psychology\" FLOAT, \n",
      "\t\"Politics\" FLOAT, \n",
      "\t\"Mathematics\" FLOAT, \n",
      "\t\"Physics\" FLOAT, \n",
      "\t\"Internet\" FLOAT, \n",
      "\t\"PC\" FLOAT, \n",
      "\t\"Economy Management\" FLOAT, \n",
      "\t\"Biology\" FLOAT, \n",
      "\t\"Chemistry\" FLOAT, \n",
      "\t\"Reading\" FLOAT, \n",
      "\t\"Geography\" FLOAT, \n",
      "\t\"Foreign languages\" FLOAT, \n",
      "\t\"Medicine\" FLOAT, \n",
      "\t\"Law\" FLOAT, \n",
      "\t\"Cars\" FLOAT, \n",
      "\t\"Art exhibitions\" FLOAT, \n",
      "\t\"Religion\" FLOAT, \n",
      "\t\"Countryside, outdoors\" FLOAT, \n",
      "\t\"Dancing\" FLOAT, \n",
      "\t\"Musical instruments\" FLOAT, \n",
      "\t\"Writing\" FLOAT, \n",
      "\t\"Passive sport\" FLOAT, \n",
      "\t\"Active sport\" FLOAT, \n",
      "\t\"Gardening\" FLOAT, \n",
      "\t\"Celebrities\" FLOAT, \n",
      "\t\"Shopping\" FLOAT, \n",
      "\t\"Science and technology\" FLOAT, \n",
      "\t\"Theatre\" FLOAT, \n",
      "\t\"Fun with friends\" FLOAT, \n",
      "\t\"Adrenaline sports\" FLOAT, \n",
      "\t\"Pets\" FLOAT, \n",
      "\t\"Flying\" FLOAT, \n",
      "\t\"Storm\" FLOAT, \n",
      "\t\"Darkness\" FLOAT, \n",
      "\t\"Heights\" FLOAT, \n",
      "\t\"Spiders\" FLOAT, \n",
      "\t\"Snakes\" BIGINT, \n",
      "\t\"Rats\" FLOAT, \n",
      "\t\"Ageing\" FLOAT, \n",
      "\t\"Dangerous dogs\" FLOAT, \n",
      "\t\"Fear of public speaking\" FLOAT, \n",
      "\t\"Smoking\" TEXT, \n",
      "\t\"Alcohol\" TEXT, \n",
      "\t\"Healthy eating\" FLOAT, \n",
      "\t\"Daily events\" FLOAT, \n",
      "\t\"Prioritising workload\" FLOAT, \n",
      "\t\"Writing notes\" FLOAT, \n",
      "\t\"Workaholism\" FLOAT, \n",
      "\t\"Thinking ahead\" FLOAT, \n",
      "\t\"Final judgement\" FLOAT, \n",
      "\t\"Reliability\" FLOAT, \n",
      "\t\"Keeping promises\" FLOAT, \n",
      "\t\"Loss of interest\" FLOAT, \n",
      "\t\"Friends versus money\" FLOAT, \n",
      "\t\"Funniness\" FLOAT, \n",
      "\t\"Fake\" FLOAT, \n",
      "\t\"Criminal damage\" FLOAT, \n",
      "\t\"Decision making\" FLOAT, \n",
      "\t\"Elections\" FLOAT, \n",
      "\t\"Self-criticism\" FLOAT, \n",
      "\t\"Judgment calls\" FLOAT, \n",
      "\t\"Hypochondria\" FLOAT, \n",
      "\t\"Empathy\" FLOAT, \n",
      "\t\"Eating to survive\" BIGINT, \n",
      "\t\"Giving\" FLOAT, \n",
      "\t\"Compassion to animals\" FLOAT, \n",
      "\t\"Borrowed stuff\" FLOAT, \n",
      "\t\"Loneliness\" FLOAT, \n",
      "\t\"Cheating in school\" FLOAT, \n",
      "\t\"Health\" FLOAT, \n",
      "\t\"Changing the past\" FLOAT, \n",
      "\t\"God\" FLOAT, \n",
      "\t\"Dreams\" BIGINT, \n",
      "\t\"Charity\" FLOAT, \n",
      "\t\"Number of friends\" BIGINT, \n",
      "\t\"Punctuality\" TEXT, \n",
      "\t\"Lying\" TEXT, \n",
      "\t\"Waiting\" FLOAT, \n",
      "\t\"New environment\" FLOAT, \n",
      "\t\"Mood swings\" FLOAT, \n",
      "\t\"Appearence and gestures\" FLOAT, \n",
      "\t\"Socializing\" FLOAT, \n",
      "\t\"Achievements\" FLOAT, \n",
      "\t\"Responding to a serious letter\" FLOAT, \n",
      "\t\"Children\" FLOAT, \n",
      "\t\"Assertiveness\" FLOAT, \n",
      "\t\"Getting angry\" FLOAT, \n",
      "\t\"Knowing the right people\" FLOAT, \n",
      "\t\"Public speaking\" FLOAT, \n",
      "\t\"Unpopularity\" FLOAT, \n",
      "\t\"Life struggles\" FLOAT, \n",
      "\t\"Happiness in life\" FLOAT, \n",
      "\t\"Energy levels\" FLOAT, \n",
      "\t\"Small - big dogs\" FLOAT, \n",
      "\t\"Personality\" FLOAT, \n",
      "\t\"Finding lost valuables\" FLOAT, \n",
      "\t\"Getting up\" FLOAT, \n",
      "\t\"Interests or hobbies\" FLOAT, \n",
      "\t\"Parents' advice\" FLOAT, \n",
      "\t\"Questionnaires or polls\" FLOAT, \n",
      "\t\"Internet usage\" TEXT, \n",
      "\t\"Finances\" FLOAT, \n",
      "\t\"Shopping centres\" FLOAT, \n",
      "\t\"Branded clothing\" FLOAT, \n",
      "\t\"Entertainment spending\" FLOAT, \n",
      "\t\"Spending on looks\" FLOAT, \n",
      "\t\"Spending on gadgets\" BIGINT, \n",
      "\t\"Spending on healthy eating\" FLOAT, \n",
      "\t\"Age\" FLOAT, \n",
      "\t\"Height\" FLOAT, \n",
      "\t\"Weight\" FLOAT, \n",
      "\t\"Number of siblings\" FLOAT, \n",
      "\t\"Gender\" TEXT, \n",
      "\t\"Left - right handed\" TEXT, \n",
      "\t\"Education\" TEXT, \n",
      "\t\"Only child\" TEXT, \n",
      "\t\"Village - town\" TEXT, \n",
      "\t\"House - block of flats\" TEXT\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "with engine.connect() as conn, conn.begin():\n",
    "    sqlite_master = pd.read_sql_query(\"SELECT * FROM sqlite_master\", conn)\n",
    "sqlite_master['sql_fmt'] = sqlite_master['sql'].apply(lambda z: [x.strip().strip(',').rsplit(' ', maxsplit=1) for x in z.split('\\n')[1:-1]])\n",
    "\n",
    "table_desc_dict = {}\n",
    "for _, row in sqlite_master.iterrows():\n",
    "    table_desc_dict[row['name']] = row['sql']\n",
    "\n",
    "schema = table_desc_dict[table_name]\n",
    "print(schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt LLM to generate SQL\n",
    "You can use your LLM of choice to generate SQL commands, but models specifically fine-tuned to generate high-quality SQL are obviously prefered. We will use the model [`sqlcoder-7b-2` by Defog](https://huggingface.co/defog/sqlcoder-7b-2), which was derived by finetunig the `llama-2` model released by Meta.\n",
    "\n",
    "While we will be prompting the model as described by the model's creators, feel free to experiment with other models and other prompt templates. Other popular LLMs for code generation are [`Deepseek-Coder-V2` by DeepSeek (æ·±åº¦æ±‚ç´¢)](https://huggingface.co/deepseek-ai/DeepSeek-Coder-V2-Instruct) and [`CodeQwen1.5-7B-Chat` by Qwen](https://huggingface.co/Qwen/CodeQwen1.5-7B-Chat)\n",
    "\n",
    "### SQLgen Benchmarks\n",
    "<details>\n",
    "<summary> BIRD-SQL </summary>\n",
    "\n",
    "[BIRD](https://bird-bench.github.io/) (BIg Bench for LaRge-scale Database Grounded Text-to-SQL Evaluation) represents a pioneering, cross-domain dataset that examines the impact of extensive database contents on text-to-SQL parsing. BIRD contains over 12,751 unique question-answer pairs, 95 big databases with a total size of 33.4  GB. It also covers more than 37 professional domains, such as blockchain, hockey, healthcare and education, etc.  \n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> Spider 1.0 </summary>\n",
    "\n",
    "[Spider 1.0](https://yale-lily.github.io/spider) is a large-scale comlpex and cross-domain semantic parsing and text-to-SQL dataset annotated by 11 Yale students. The goal of the Spider challenge is to develop natural language interfaces to cross-domain databases. It consists of 10,181 questions and 5,693 unique complex SQL queries on 200 databases with multiple tables covering 138 different domains.  \n",
    "\n",
    "</details>\n",
    "\n",
    "\n",
    "### LLM Benchmarks\n",
    "<details>\n",
    "<summary> HumanEval </summary>\n",
    "\n",
    "[HumanEval](https://paperswithcode.com/dataset/humaneval) problem solving dataset is introduced in the paper \"Evaluating Large Language Models Trained on Code\". It used to measure functional correctness for synthesizing programs from docstrings. It consists of 164 original programming problems, assessing language comprehension, algorithms, and simple mathematics, with some comparable to simple software interview questions.\n",
    "\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> EvalPlus </summary>\n",
    "\n",
    "[EvalPlus](https://github.com/evalplus/evalplus) is a rigorous evaluation framework for LLM4Code, with:  \n",
    "âœ¨ HumanEval+: 80x more tests than the original HumanEval!  \n",
    "âœ¨ MBPP+: 35x more tests than the original MBPP!  \n",
    "[...]  \n",
    "Why EvalPlus? What does using EvalPlus datasets bring to you?  \n",
    "âœ¨ Reliable ranking: See our leaderboard for the latest LLM ranking before and after rigorous evaluation.  \n",
    "âœ¨ Code robustness: Look at the score differences! esp. before (e.g., HumanEval) and after (e.g., HumanEval+) using EvalPlus! The drop/gap indicates if the LLM can generate more robust code: less drop means more robustness and a larger drop means the code tends to be more fragile.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> InfiCoder-eval </summary>\n",
    "\n",
    "[InfiCoder-eval](https://infi-coder.github.io/inficoder-eval) is a large-scale free-form question-answering (QA) benchmark for code. InfiCoder-Eval comprises 270 carefully picked high-quality StackOverflow questions, covering 18 programming languages. [...] As confirmed with human experiments, InfiCoder-Eval evaluation aligns with humans better than model-based evaluation and runs much faster at the same time. [...] Existing benchmarks weigh heavily on code generation, unit-test-based evaluation, and a limited set of programming languages. InfiCoder-Eval processes a much higher diversity to reflect real-world code LLMsâ€™ usage scenarios and is far from saturation.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> LMSYS Chatbot Arena Leaderboard </summary>\n",
    "\n",
    "[LMSYS Chatbot Arena](https://huggingface.co/spaces/lmsys/chatbot-arena-leaderboard) is a crowdsourced open platform for LLM evals. We've collected over 200,000 human preference votes to rank LLMs with the Elo ranking system.\n",
    "</details>\n",
    "\n",
    "<details>\n",
    "<summary> Big Code Models Leaderboard </summary>\n",
    "\n",
    "[Big Code Models Leaderboard (open source models only)](https://huggingface.co/spaces/bigcode/bigcode-models-leaderboard) compares performance of base multilingual code generation models on HumanEval benchmark and MultiPL-E. We also measure throughput and provide information about the models. We only compare open pre-trained multilingual code models, that people can start from as base models for their trainings. Win Rate represents how often a model outperforms other models in each language, averaged across all languages. The scores of instruction-tuned models might be significantly higher on humaneval-python than other languages. [...] HumanEval-Python reports the pass@1 on HumanEval; the rest is from MultiPL-E benchmark. For all languages, we use the original benchamrk prompts for all models except HumanEval-Python, where we separate base from instruction models.\n",
    "</details>\n",
    "\n",
    "\n",
    "<!-- ![](assets/state-of-codeLLMs.PNG)   -->\n",
    "<img src='assets/state-of-codeLLMs.PNG'>  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](assets/Training-code-LLMs.PNG)   -->\n",
    "<img src='assets/Training-code-LLMs.PNG'>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cloud-user/data/miniconda3/envs/myenv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code downloads the SQLCoder 7B model to your environment. The model weights total 13.6 GB so depending on your internet connection it might take a while. \n",
    "    \n",
    "If you have less than 16 GB of GPU RAM, you can choose to enable the `load_in_8bit=True` line and comment out `torch_dtype=torch.float16`. This will however increase the time it takes for the model to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [04:04<00:00, 81.54s/it]\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:02<00:00,  1.12it/s]\n"
     ]
    }
   ],
   "source": [
    "model_name = \"defog/sqlcoder-7b-2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    # torch_dtype=torch.float16, # Disable if enabling the below line\n",
    "    load_in_8bit=True, # Disable if enabling the above line\n",
    "    device_map=\"auto\",\n",
    "    use_cache=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- ![](assets/evaluation-NL2SQL.PNG)   -->\n",
    "<img src='assets/evaluation-NL2SQL.PNG'>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_query(prompt, device='cpu'):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "    generated_ids = model.generate(\n",
    "        **inputs,\n",
    "        num_return_sequences=1,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        max_new_tokens=400,\n",
    "        do_sample=False,\n",
    "        num_beams=1,\n",
    "    )\n",
    "    outputs = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n",
    "    \n",
    "    if device == 'cuda':\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.synchronize()\n",
    "        # empty cache so that you do generate more results w/o memory crashing\n",
    "        # particularly important on Colab â€“ memory management is much more straightforward\n",
    "        # when running on an inference service\n",
    "    return outputs[0].split(\"[SQL]\")[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finetuned LLMs are very sensitive to the prompt. Make sure you are using the prompt format specified by the creators of the model. You can usually get this information in the HuggingFace model card or in Github repos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Task\n",
      "Generate a SQL query to answer [QUESTION]Which are the rows which have 1 for at least one music related column?[/QUESTION] \n",
      "\n",
      "### Instructions\n",
      "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
      "\n",
      "## Database Schema \n",
      "This query will run on a database whose schema is represented in this string: CREATE TABLE \"young-people-survey\" (\n",
      "\t\"Music\" FLOAT, \n",
      "\t\"Slow songs or fast songs\" FLOAT, \n",
      "\t\"Dance\" FLOAT, \n",
      "\t\"Folk\" FLOAT, \n",
      "\t\"Country\" FLOAT, \n",
      "\t\"Classical music\" FLOAT, \n",
      "\t\"Musical\" FLOAT, \n",
      "\t\"Pop\" FLOAT, \n",
      "\t\"Rock\" FLOAT, \n",
      "\t\"Metal or Hardrock\" FLOAT, \n",
      "\t\"Punk\" FLOAT, \n",
      "\t\"Hiphop, Rap\" FLOAT, \n",
      "\t\"Reggae, Ska\" FLOAT, \n",
      "\t\"Swing, Jazz\" FLOAT, \n",
      "\t\"Rock n roll\" FLOAT, \n",
      "\t\"Alternative\" FLOAT, \n",
      "\t\"Latino\" FLOAT, \n",
      "\t\"Techno, Trance\" FLOAT, \n",
      "\t\"Opera\" FLOAT, \n",
      "\t\"Movies\" FLOAT, \n",
      "\t\"Horror\" FLOAT, \n",
      "\t\"Thriller\" FLOAT, \n",
      "\t\"Comedy\" FLOAT, \n",
      "\t\"Romantic\" FLOAT, \n",
      "\t\"Sci-fi\" FLOAT, \n",
      "\t\"War\" FLOAT, \n",
      "\t\"Fantasy/Fairy tales\" FLOAT, \n",
      "\t\"Animated\" FLOAT, \n",
      "\t\"Documentary\" FLOAT, \n",
      "\t\"Western\" FLOAT, \n",
      "\t\"Action\" FLOAT, \n",
      "\t\"History\" FLOAT, \n",
      "\t\"Psychology\" FLOAT, \n",
      "\t\"Politics\" FLOAT, \n",
      "\t\"Mathematics\" FLOAT, \n",
      "\t\"Physics\" FLOAT, \n",
      "\t\"Internet\" FLOAT, \n",
      "\t\"PC\" FLOAT, \n",
      "\t\"Economy Management\" FLOAT, \n",
      "\t\"Biology\" FLOAT, \n",
      "\t\"Chemistry\" FLOAT, \n",
      "\t\"Reading\" FLOAT, \n",
      "\t\"Geography\" FLOAT, \n",
      "\t\"Foreign languages\" FLOAT, \n",
      "\t\"Medicine\" FLOAT, \n",
      "\t\"Law\" FLOAT, \n",
      "\t\"Cars\" FLOAT, \n",
      "\t\"Art exhibitions\" FLOAT, \n",
      "\t\"Religion\" FLOAT, \n",
      "\t\"Countryside, outdoors\" FLOAT, \n",
      "\t\"Dancing\" FLOAT, \n",
      "\t\"Musical instruments\" FLOAT, \n",
      "\t\"Writing\" FLOAT, \n",
      "\t\"Passive sport\" FLOAT, \n",
      "\t\"Active sport\" FLOAT, \n",
      "\t\"Gardening\" FLOAT, \n",
      "\t\"Celebrities\" FLOAT, \n",
      "\t\"Shopping\" FLOAT, \n",
      "\t\"Science and technology\" FLOAT, \n",
      "\t\"Theatre\" FLOAT, \n",
      "\t\"Fun with friends\" FLOAT, \n",
      "\t\"Adrenaline sports\" FLOAT, \n",
      "\t\"Pets\" FLOAT, \n",
      "\t\"Flying\" FLOAT, \n",
      "\t\"Storm\" FLOAT, \n",
      "\t\"Darkness\" FLOAT, \n",
      "\t\"Heights\" FLOAT, \n",
      "\t\"Spiders\" FLOAT, \n",
      "\t\"Snakes\" BIGINT, \n",
      "\t\"Rats\" FLOAT, \n",
      "\t\"Ageing\" FLOAT, \n",
      "\t\"Dangerous dogs\" FLOAT, \n",
      "\t\"Fear of public speaking\" FLOAT, \n",
      "\t\"Smoking\" TEXT, \n",
      "\t\"Alcohol\" TEXT, \n",
      "\t\"Healthy eating\" FLOAT, \n",
      "\t\"Daily events\" FLOAT, \n",
      "\t\"Prioritising workload\" FLOAT, \n",
      "\t\"Writing notes\" FLOAT, \n",
      "\t\"Workaholism\" FLOAT, \n",
      "\t\"Thinking ahead\" FLOAT, \n",
      "\t\"Final judgement\" FLOAT, \n",
      "\t\"Reliability\" FLOAT, \n",
      "\t\"Keeping promises\" FLOAT, \n",
      "\t\"Loss of interest\" FLOAT, \n",
      "\t\"Friends versus money\" FLOAT, \n",
      "\t\"Funniness\" FLOAT, \n",
      "\t\"Fake\" FLOAT, \n",
      "\t\"Criminal damage\" FLOAT, \n",
      "\t\"Decision making\" FLOAT, \n",
      "\t\"Elections\" FLOAT, \n",
      "\t\"Self-criticism\" FLOAT, \n",
      "\t\"Judgment calls\" FLOAT, \n",
      "\t\"Hypochondria\" FLOAT, \n",
      "\t\"Empathy\" FLOAT, \n",
      "\t\"Eating to survive\" BIGINT, \n",
      "\t\"Giving\" FLOAT, \n",
      "\t\"Compassion to animals\" FLOAT, \n",
      "\t\"Borrowed stuff\" FLOAT, \n",
      "\t\"Loneliness\" FLOAT, \n",
      "\t\"Cheating in school\" FLOAT, \n",
      "\t\"Health\" FLOAT, \n",
      "\t\"Changing the past\" FLOAT, \n",
      "\t\"God\" FLOAT, \n",
      "\t\"Dreams\" BIGINT, \n",
      "\t\"Charity\" FLOAT, \n",
      "\t\"Number of friends\" BIGINT, \n",
      "\t\"Punctuality\" TEXT, \n",
      "\t\"Lying\" TEXT, \n",
      "\t\"Waiting\" FLOAT, \n",
      "\t\"New environment\" FLOAT, \n",
      "\t\"Mood swings\" FLOAT, \n",
      "\t\"Appearence and gestures\" FLOAT, \n",
      "\t\"Socializing\" FLOAT, \n",
      "\t\"Achievements\" FLOAT, \n",
      "\t\"Responding to a serious letter\" FLOAT, \n",
      "\t\"Children\" FLOAT, \n",
      "\t\"Assertiveness\" FLOAT, \n",
      "\t\"Getting angry\" FLOAT, \n",
      "\t\"Knowing the right people\" FLOAT, \n",
      "\t\"Public speaking\" FLOAT, \n",
      "\t\"Unpopularity\" FLOAT, \n",
      "\t\"Life struggles\" FLOAT, \n",
      "\t\"Happiness in life\" FLOAT, \n",
      "\t\"Energy levels\" FLOAT, \n",
      "\t\"Small - big dogs\" FLOAT, \n",
      "\t\"Personality\" FLOAT, \n",
      "\t\"Finding lost valuables\" FLOAT, \n",
      "\t\"Getting up\" FLOAT, \n",
      "\t\"Interests or hobbies\" FLOAT, \n",
      "\t\"Parents' advice\" FLOAT, \n",
      "\t\"Questionnaires or polls\" FLOAT, \n",
      "\t\"Internet usage\" TEXT, \n",
      "\t\"Finances\" FLOAT, \n",
      "\t\"Shopping centres\" FLOAT, \n",
      "\t\"Branded clothing\" FLOAT, \n",
      "\t\"Entertainment spending\" FLOAT, \n",
      "\t\"Spending on looks\" FLOAT, \n",
      "\t\"Spending on gadgets\" BIGINT, \n",
      "\t\"Spending on healthy eating\" FLOAT, \n",
      "\t\"Age\" FLOAT, \n",
      "\t\"Height\" FLOAT, \n",
      "\t\"Weight\" FLOAT, \n",
      "\t\"Number of siblings\" FLOAT, \n",
      "\t\"Gender\" TEXT, \n",
      "\t\"Left - right handed\" TEXT, \n",
      "\t\"Education\" TEXT, \n",
      "\t\"Only child\" TEXT, \n",
      "\t\"Village - town\" TEXT, \n",
      "\t\"House - block of flats\" TEXT\n",
      ") \n",
      "\n",
      "### Answer \n",
      "Given the database schema, here is the SQL query that answers [QUESTION]Which are the rows which have 1 for at least one music related column?[/QUESTION] [SQL]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "question = 'Which are the rows which have more than 4 for at Horror and Thriller movies ?'\n",
    "\n",
    "prompt_template = \"\"\"### Task\n",
    "Generate a SQL query to answer [QUESTION]{question}[/QUESTION] \n",
    "\n",
    "### Instructions\n",
    "- If you cannot answer the question with the available database schema, return 'I do not know'\n",
    "\n",
    "## Database Schema \n",
    "This query will run on a database whose schema is represented in this string: {db_schema} \n",
    "\n",
    "### Answer \n",
    "Given the database schema, here is the SQL query that answers [QUESTION]{question}[/QUESTION] [SQL]\n",
    "\"\"\"\n",
    "\n",
    "prompt = prompt_template.format(question=question, db_schema=schema)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_sql = generate_query(prompt, device='cuda')\n",
    "print(f'SQL generated by the model: {generated_sql}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we execute the generated SQL query on our DB and verify its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"sqlite:///mysqlitedb.db\")\n",
    "\n",
    "with engine.connect() as conn, conn.begin():\n",
    "    query_result = pd.read_sql_query(generated_sql, conn)\n",
    "\n",
    "query_result[['Age','Height','Weight','Number of siblings','Gender','Horror','Thriller']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
